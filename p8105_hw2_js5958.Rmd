---
title: "P8105 HW2 | Jagjit Singh | ID: js5958"
output: github_document
date: "2022-10-02"
---

```{r}
library(tidyverse)
library(readxl)
library(dplyr)
```


### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "/Users/jag/Downloads/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```


# Problem 2

Reading the excel file and cleaning th data

```{r}
df_trash_w <- read_excel("trash_data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = "A2:N408",
    )
```

Reading Mr. Trash Wheel
```{r}

df_trash <- read_excel("trash_data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = "A2:N549",
    )

#### cleaning the data
df_trash <-
    df_trash %>%
    janitor::clean_names() %>%
    mutate(type_trash = "Mr.Trash", #new column
         volume_cubic_yards = as.character(volume_cubic_yards),
         plastic_bottles = as.character(plastic_bottles),
         polystyrene = as.character(polystyrene),
         cigarette_butts = as.character(cigarette_butts),
         glass_bottles  = as.character(glass_bottles),
         grocery_bags = as.character(grocery_bags),
         chip_bags = as.character(chip_bags),
         homes_powered = as.character(homes_powered),
         type_trash = as.character(type_trash),
         date = as.Date(date))
head(df_trash)
```


Rounding the number of sports balls to the nearest integer and converts the result to an integer variable:
```{r}
df_trash <-
  df_trash %>%
  filter(!str_detect(month, "Total")) %>%

  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))

df_trash
```

Reading professor trash wheel:
```{r}
pf_trash <- read_excel("trash_data.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:M96") %>%
  janitor::clean_names() %>%
  mutate(type_trash = "Pr.Trash", #new column
         sports_balls = 0,
         date = as.Date(date),
         year = as.character(year),
         volume_cubic_yards = as.character(volume_cubic_yards),
         plastic_bottles = as.character(plastic_bottles),
         polystyrene = as.character(polystyrene),
         cigarette_butts = as.character(cigarette_butts),
         glass_bottles  = as.character(glass_bottles),
         grocery_bags = as.character(grocery_bags),
         chip_bags = as.character(chip_bags),
         homes_powered = as.character(homes_powered),
         type_trash = as.character(type_trash),
         date = as.Date(date))

```


```{r}
merged_df <- 
  bind_rows(df_trash, pf_trash)
```


Total weight of trash collected by Professor Trash Wheel :
```{r}
tot = merged_df %>%
  filter(type_trash == "Pr.Trash") %>%
  select(weight_tons) %>%
  sum()
```
Total weight of trash collected by Professor Trash Wheel = **`r tot `**



Total number of sports balls collected by Mr. Trash Wheel in 2020 :
```{r}
tot = merged_df %>%
  filter(type_trash == "Mr.Trash") %>%
  filter(year == 2020)  %>%
  select(sports_balls) %>%
  sum()
```
Total number of sports balls collected by Mr. Trash Wheel in 2020 = **`r tot `**

Description of the merged dataframe:
```{r}
d = dim(merged_df) #dimensions
vars = merged_df %>% names()
```

The dimension of the merged data (Mr Trash Wheel and Professor Trash Wheel) is (**`r d `**) (number of rows, number of columns) and variable names are **`r vars `**.


# Problem 3

Importing and cleaning the pols-months from the FiveThirtyEight folder
```{r}
pol_df <- 
  read_csv("/Users/jag/Downloads/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names()


#Use separate() to break up the variable mon into integer variables year, 
#month, and day
pol_df <- pol_df%>%
  separate(col = mon, into = c("year","month", "day")) %>%
  mutate(across(.cols = c(year, month, day), as.integer)) %>%
  mutate(month = month.name[month]) 

#president variable taking values gop and dem
pol_df <- pol_df%>%
  mutate(president = case_when(prez_dem == 1 ~ "dem", 
                               prez_gop == 1 ~ "gop",
                              prez_gop == 2 ~ "gop")) 

#removung prez_dem and prez_gop and day
pol_df <- pol_df%>%
  select(everything(), -day, -prez_dem, -prez_gop)


```

Importing and cleaning the snp data
```{r}
snp_df <- 
  read_csv("/Users/jag/Downloads/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names()
```


```{r}
snp_df <- snp_df %>%
  separate(date, sep = "/", into = c("month", "day", "year")) %>%
  mutate(across(.cols = c(month, day, year), as.integer)) %>%
  mutate(month = month.name[month])  %>%
  mutate(year = ifelse(year > 21, 
                       1900 + year, 
                       2000 + year)) %>%
  select(year, month, close)

```

Importing and cleaning the unemployment data

```{r}
#### First we will clean the column names ####
ue_df <- read_csv("/Users/jag/Downloads/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() 


####### adjustments for the merge
ue_df <- ue_df %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percentage") 
```


Correcting the year values from the acronyms to full month names:
```{r}
ue_df <-ue_df %>%
  mutate(across(.col = c(year), as.integer)) %>%
  mutate(month = recode(month, "jan" = "January", "feb" = "February", 
                        "mar" = "March", "apr" = "April", "may" = "May",
                        "jun" = "June", "jul" = "July", "aug" = "August",
                        "sep" = "September", "oct" = "October", 
                        "nov" = "November", "dec" = "December"))
```

```{r}
pol_snp_df <- left_join(pol_df, snp_df, by = c("year", "month"))
net_df <-left_join(pol_snp_df, ue_df, by = c("year", "month"))
```

Now we will describe hese dataset and explain briefly what each dataset contained, and describe the resulting dataset:

```{r}
head(pol_df)
d = dim(pol_df) #dimensions
vars = pol_df %>% names()
range = pol_df %>% select(year) %>% range()
```
The dimension of the dataset is (**`r d `**) (number of rows, number of columns). It is essentially data on the number of candidates of the democratic and republican parties, who were in gop, sen, or gov positions. The specific variables names being **`r vars `**. The dataset contains data for years ranging **`r range `**.


The stock market dataset 
```{r}
head(snp_df)
d = dim(snp_df) #dimensions
vars = snp_df %>% names()
range = snp_df %>% select(year) %>% range()
```
This dataset contains data from monthly close prices of the S&P 500 market index. The variables being **`r vars `** . The price column is the close price for the given month. The dataset contains monthly close price for years ranging **`r range `**. The dimension of the dataset is (**`r d `**)(number of rows, number of columns).

Unemployment dataset
```{r}
head(ue_df)
d = dim(ue_df) #dimensions
vars = ue_df %>% names()
range = ue_df %>% select(year) %>% range()
```
Finally, the employment dataset contains percentage unemployment in monthly terms for years ranging  (**`r range `**) . The dimension of the dataset is (**`r d `**)(number of rows, number of columns) and the variable names are **`r vars `**.



```{r}
net_name = net_df %>% names()
d = dim(net_df)
net_range =  net_df %>% select(year) %>% range()
```
The dimension of the merged dataset is **`r d `**. The important variables are **`r net_name `**. It contains data for years ranging (**`r net_range `**)